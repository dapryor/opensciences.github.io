---
title: JavaScript and html Validity Errors
excerpt: "A Framework for Automated Testing of JavaScript Web Applications"
layout: repo-dataset
authors: "Shay Artzi; Julian Dolby; Simon Holm Jensen; Anders Møller; Frank Tip"
version: 4
---

#URL

* [Data in tera-PROMISE](https://terapromise.csc.ncsu.edu:8443/!/#repo/view/head/other/errors)
* [Paper in IEEE Digital Library](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6032496)

#Change Log

When | What
---- | ----
 September 10th, 2015 | Donated by [Julian Dolby](mailto:dolby@us.ibm.com)

#Reference

Studies who have been using the data (in any form) are required to include the following reference:

```
@InProceedings{artemis2011,
author = {Shay Artzi and Julian Dolby and Simon Holm Jensen and
Anders M\o{}ller and Frank Tip},
title = {A Framework for Automated Testing of {J}ava{S}cript Web Applications},
booktitle = {Proc. 33rd International Conference on Software Engineering (ICSE)},
year = {2011},
month = {May},
}
```

#About the Data

##Overview of Data

This data is captured by tool ‘Artemis’, which is a test generation tool for javascript based web applications. The data contained here has benchmarks and html validity errors found out by Artemis tool, when ran against live applications. This data can be used to analyse the html coding errors committed by the programmers and see how we can prevent these errors.

##Paper Abstract

Current practice in testing JavaScript web applications requires manual construction of test cases, which is difficult and tedious. We present a framework for feedback-directed automated test generation for JavaScript in which execution is monitored to collect information that directs the test generator towards inputs that yield increased coverage. We implemented several instantiations of the framework, corresponding to variations on feedback-directed random testing, in a tool called Artemis. Experiments on a suite of JavaScript applications demonstrate that a simple instantiation of the framework that uses event handler registrations as feedback information produces surprisingly good coverage if enough tests are generated. By also using coverage information and read-write sets as feedback information, a slightly better level of coverage can be achieved, and sometimes with many fewer tests. The generated tests can be used for detecting HTML validity problems and other programming errors.
